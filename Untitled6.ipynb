{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41ff46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7d09c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[1;32m---> 17\u001b[0m     rank \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     18\u001b[0m     name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     19\u001b[0m     artist \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "columns = [th.text.strip() for th in table.find_all('th')]\n",
    "rows = [tr.find_all('td') for tr in table.find_all('tr')]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    rank = row[0].text.strip()\n",
    "    name = row[1].text.strip()\n",
    "    artist = row[2].text.strip()\n",
    "    upload_date = row[3].text.strip()\n",
    "    views = row[4].text.strip()\n",
    "    data.append({\n",
    "        'Rank': rank,\n",
    "        'Name': name,\n",
    "        'Artist': artist,\n",
    "        'Upload Date': upload_date,\n",
    "        'Views': views\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a0940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa32a3e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m fixtures_container \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfixtures\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Extract the series, place, date, and time for each fixture\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m fixtures \u001b[38;5;241m=\u001b[39m [fixture\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfixture\u001b[39m\u001b[38;5;124m'\u001b[39m}) \u001b[38;5;28;01mfor\u001b[39;00m fixture \u001b[38;5;129;01min\u001b[39;00m fixtures_container]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Create a list to store the data\u001b[39;00m\n\u001b[0;32m     21\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.bcci.tv/international-fixtures'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "fixtures_container = soup.find('div', {'class': 'fixtures'})\n",
    "\n",
    "fixtures = [fixture.find_all('div', {'class': 'fixture'}) for fixture in fixtures_container]\n",
    "\n",
    "data = []\n",
    "\n",
    "for fixture in fixtures:\n",
    "    series = fixture[0].text.strip()\n",
    "    place = fixture[1].text.strip()\n",
    "    date = fixture[2].text.strip()\n",
    "    time = fixture[3].text.strip()\n",
    "    data.append({'Series': series, 'Place': place, 'Date': date, 'Time': time})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc59fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8301d744",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Extract the column headers\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m headers \u001b[38;5;241m=\u001b[39m [th\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m th \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Extract the rows containing the GDP data\u001b[39;00m\n\u001b[0;32m     21\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://statisticstimes.com/economy/gdp-of-indian-states/'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "headers = [th.text.strip() for th in table.find_all('th')]\n",
    "\n",
    "rows = []\n",
    "for tr in table.find_all('tr'):\n",
    "    rows.append([td.text.strip() for td in tr.find_all('td')])\n",
    "\n",
    "data = {}\n",
    "\n",
    "for row in rows:\n",
    "    state = row[0].lower()\n",
    "    data[state] = {\n",
    "        'Rank': int(row[1]),\n",
    "        'State': state,\n",
    "        'GSDP(18-19)': float(row[2].replace(',', '')),\n",
    "        'GSDP(19-20)': float(row[3].replace(',', '')),\n",
    "        'Share(18-19)': float(row[4].replace(',', '')),\n",
    "        'GDP($ billion)': float(row[5].replace(',', ''))\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a6f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bf67501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://github.com/trending\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "repositories = soup.find_all(\"div\", class_=\"repo\")\n",
    "\n",
    "for repository in repositories:\n",
    "    title = repository.find(\"a\", class_=\"repo-name\").text.strip()\n",
    "    description = repository.find(\"p\", class_=\"repo-description\").text.strip()\n",
    "    contributors = repository.find(\"span\", class_=\"contributors\").text.strip()\n",
    "    language = repository.find(\"span\", class_=\"language\").text.strip()\n",
    "    \n",
    "    print(f\"Repository Title: {title}\")\n",
    "    print(f\"Repository Description: {description}\")\n",
    "    print(f\"Contributors Count: {contributors}\")\n",
    "    print(f\"Language Used: {language}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7cd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9702337",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchart-table\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Extract the column headers\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m headers \u001b[38;5;241m=\u001b[39m [th\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m th \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Extract the rows containing the song details\u001b[39;00m\n\u001b[0;32m     20\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.billboard.com/charts/hot-100\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', class_='chart-table')\n",
    "\n",
    "headers = [th.text.strip() for th in table.find_all('th')]\n",
    "\n",
    "rows = []\n",
    "for tr in table.find_all('tr'):\n",
    "    rows.append([td.text.strip() for td in tr.find_all('td')])\n",
    "\n",
    "songs = []\n",
    "\n",
    "for row in rows:\n",
    "    songs.append({\n",
    "        'song_name': row[0],\n",
    "        'artist_name': row[1],\n",
    "        'last_week_rank': row[2],\n",
    "        'peak_rank': row[3],\n",
    "        'weeks_on_board': row[4]\n",
    "    })\n",
    "\n",
    "# Print the song details\n",
    "for song in songs:\n",
    "    print(song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15980ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91a04fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Category:Best-selling_novels\"\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "novels = soup.find_all('li', class_='mw-parser-output')\n",
    "\n",
    "novel_details = []\n",
    "\n",
    "for novel in novels:\n",
    "    title = novel.find('h2', class_='mw-parser-output').text.strip()\n",
    "    author = novel.find('span', class_='mw-parser-output').text.strip()\n",
    "\n",
    "    sales = novel.find('span', class_='sales').text.strip()\n",
    "    publisher = novel.find('span', class_='publisher').text.strip()\n",
    "\n",
    "    genre = novel.find('span', class_='genre').text.strip()\n",
    "\n",
    "    novel_details.append({\n",
    "        'book_name': title,\n",
    "        'author_name': author,\n",
    "        'volumes_sold': sales,\n",
    "        'publisher': publisher,\n",
    "        'genre': genre\n",
    "    })\n",
    "\n",
    "# Print the novel details\n",
    "print(novel_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125eb47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0788f22a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle_list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Extract the column headers\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m headers \u001b[38;5;241m=\u001b[39m [th\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m th \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Extract the rows containing the TV series information\u001b[39;00m\n\u001b[0;32m     16\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find(\"table\", class_=\"title_list\")\n",
    "\n",
    "headers = [th.text.strip() for th in table.find_all(\"th\")]\n",
    "\n",
    "rows = []\n",
    "for tr in table.find_all(\"tr\"):\n",
    "    rows.append([td.text.strip() for td in tr.find_all(\"td\")])\n",
    "\n",
    "tv_series = []\n",
    "\n",
    "for row in rows:\n",
    "    name = row[0]\n",
    "    year_span = row[1]\n",
    "    genre = row[2]\n",
    "    run_time = row[3]\n",
    "    ratings = row[4]\n",
    "    votes = row[5]\n",
    "\n",
    "    tv_series.append({\n",
    "        \"Name\": name,\n",
    "        \"Year span\": year_span,\n",
    "        \"Genre\": genre,\n",
    "        \"Run time\": run_time,\n",
    "        \"Ratings\": ratings,\n",
    "        \"Votes\": votes\n",
    "    })\n",
    "\n",
    "for tv_series_item in tv_series:\n",
    "    print(tv_series_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d430e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "145cbd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find the link to the Show All Dataset page.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "all_datasets_link = soup.find(\"a\", {\"href\": \"/ml/datasets.php\"})\n",
    "\n",
    "if all_datasets_link:\n",
    "    all_datasets_url = url + all_datasets_link[\"href\"]\n",
    "\n",
    "    datasets_response = requests.get(all_datasets_url)\n",
    "    \n",
    "    datasets_soup = BeautifulSoup(datasets_response.content, \"html.parser\")\n",
    "    \n",
    "    dataset_table = datasets_soup.find(\"table\", {\"cellpadding\": \"3\"})\n",
    "    \n",
    "    dataset_names = []\n",
    "    data_types = []\n",
    "    tasks = []\n",
    "    attribute_types = []\n",
    "    num_instances = []\n",
    "    num_attributes = []\n",
    "    years = []\n",
    "\n",
    "    # Extract data from the table rows\n",
    "    for row in dataset_table.find_all(\"tr\")[1:]:\n",
    "        columns = row.find_all(\"td\")\n",
    "        dataset_name = columns[0].text.strip()\n",
    "        dataset_names.append(dataset_name)\n",
    "\n",
    "        data_type = columns[1].text.strip()\n",
    "        data_types.append(data_type)\n",
    "\n",
    "        task = columns[2].text.strip()\n",
    "        tasks.append(task)\n",
    "\n",
    "        attribute_type = columns[3].text.strip()\n",
    "        attribute_types.append(attribute_type)\n",
    "\n",
    "        num_instance = columns[4].text.strip()\n",
    "        num_instances.append(num_instance)\n",
    "\n",
    "        num_attribute = columns[5].text.strip()\n",
    "        num_attributes.append(num_attribute)\n",
    "\n",
    "        year = columns[6].text.strip()\n",
    "        years.append(year)\n",
    "\n",
    "    # Print or use the data as needed\n",
    "    for i in range(len(dataset_names)):\n",
    "        print(f\"Dataset Name: {dataset_names[i]}\")\n",
    "        print(f\"Data Type: {data_types[i]}\")\n",
    "        print(f\"Task: {tasks[i]}\")\n",
    "        print(f\"Attribute Type: {attribute_types[i]}\")\n",
    "        print(f\"No. of Instances: {num_instances[i]}\")\n",
    "        print(f\"No. of Attributes: {num_attributes[i]}\")\n",
    "        print(f\"Year: {years[i]}\")\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "else:\n",
    "    print(\"Couldn't find the link to the Show All Dataset page.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8925eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c0f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b70841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb89d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37298a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b7d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee7db00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e66092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c392e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2c9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415c89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479563c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e207cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40476614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a442807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe697899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef1d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68756ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cecb247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cdc9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92716f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
